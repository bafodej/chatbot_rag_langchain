{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Chatbot - Indeed Job Search France\n",
    "\n",
    "Pipeline RAG pour analyser les offres d'emploi Indeed en France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuration et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom dotenv import load_dotenv\n\n# Charger les variables d'environnement (optionnel avec Ollama)\nload_dotenv()\n\n# Plus besoin de cle API avec Ollama !\nprint(\"Environnement charge - Ollama tourne en local (100% gratuit)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain_community.document_loaders import WebBaseLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.llms import Ollama\nfrom langchain_community.embeddings import OllamaEmbeddings\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import ChatPromptTemplate  \nfrom langchain_core.output_parsers import StrOutputParser  \nfrom langchain_core.runnables import RunnablePassthrough  \n\nprint(\"Bibliotheques LangChain 2025 importees (Ollama - 100% gratuit)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Scraping Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_indeed(query=\"\"):\n",
    "    \"\"\"Scrappe les offres d'emploi Indeed France\"\"\"\n",
    "    url = f\"https://fr.indeed.com/emplois?q={query}\"\n",
    "    print(f\"Scraping: {url}\")\n",
    "    \n",
    "    # WebBaseLoader avec headers personnalises\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=[url],\n",
    "        header_template={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    docs = loader.load()\n",
    "    print(f\"Documents scrapes: {len(docs)}\")\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du scraping -  requete a modifier selon les besoins\n",
    "query = \"data analyst\"  # ex: 'python', 'alternance', 'IA', etc.\n",
    "docs = scrape_indeed(query)\n",
    "\n",
    "if docs:\n",
    "    print(f\"\\nPremiers 500 caracteres:\\n{docs[0].page_content[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Division des documents en chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# Division des documents\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"Total de chunks: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creation de la base vectorielle ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialisation des embeddings (Ollama - gratuit, local)\nembeddings = OllamaEmbeddings(model=\"llama3.2\")\n\n# Creation du vector store\nvectorstore = Chroma.from_documents(\n    documents=splits,\n    embedding=embeddings,\n    persist_directory=\"./chroma_db\"\n)\n\nprint(\"Vector store cree\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuration de la chaine RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Template de prompt personnalise\ntemplate = \"\"\"Tu es un analyste offres d'emploi en France.\n\nCONTEXTE SCRAPE (Indeed France):\n{context}\n\nQUESTION: {question}\n\nInstructions:\n1. Reponds precisement avec chiffres exacts\n2. Cite les entreprises et lieux quand disponible\n3. Maximum 3-4 phrases concises\n4. Francais uniquement\n\nReponse:\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\n# Initialisation du LLM Ollama (100% gratuit, local)\nllm = Ollama(model=\"llama3.2\", temperature=0)\n\n# Creation du retriever\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n\n# Creation de la chaine RAG avec LCEL\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(\"Chaine RAG prete (Ollama llama3.2)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test des requetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_chatbot(question):\n",
    "    \"\"\"Poser une question au chatbot RAG\"\"\"\n",
    "    reponse = rag_chain.invoke(question)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"R: {reponse}\\n\")\n",
    "    return reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de requetes - testez differentes questions!\n",
    "ask_chatbot(\"Combien d'offres data analyst ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_chatbot(\"Quelles offres a Lille ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_chatbot(\"Top 5 entreprises qui recrutent ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_chatbot(\"Quels sont les salaires proposes ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}